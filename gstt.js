"use strict";

const fs = require("fs");
const path = require("path");
const express = require("express");
const http = require("http");
const { server: WebSocketServer } = require("websocket");
const speech = require('@google-cloud/speech');
const { DialogflowCXService } = require('./dialogflow-service'); // Import the service

const app = express();
const HTTP_SERVER_PORT = process.env.PORT || 8081;

// Add express middleware
app.use(express.urlencoded({ extended: true }));
app.use(express.json());

// Create Google Speech client
const speechClient = new speech.SpeechClient();

// Initialize DialogFlow service
const dialogflowService = new DialogflowCXService();

// Create an HTTP server and bind it to Express
const server = http.createServer(app);

// WebSocket server over the same HTTP server
const mediaws = new WebSocketServer({
  httpServer: server,
  autoAcceptConnections: true,
});

// Store active calls
const activeCalls = new Map();

class AudioBuffer {
  constructor() {
    this.audioChunks = [];
    this.processingInterval = null;
    this.processingIntervalTime = 4000;
    this.isRecording = false;
    this.lastProcessTime = 0;
    this.chunkCount = 0;
    this.minChunksBeforeProcessing = 100;
    
    // Session identifiers
    this.sessionId = null;
    this.callSid = null;
    this.streamSid = null;
    this.accountSid = null;
    this.fromNumber = null;
    this.toNumber = null;
    this.fromCountry = null;
    this.toCountry = null;
    this.fromLocation = null;
    this.sessionStartTime = null;
    
    // Dialogflow session ID (use phone number for conversation continuity)
    this.dialogflowSessionId = null;
  }

  setSessionInfo(webSocketData, callInfo = null) {
    this.sessionId = webSocketData.callSid;
    this.callSid = webSocketData.callSid;
    this.streamSid = webSocketData.streamSid;
    this.accountSid = webSocketData.accountSid;
    this.sessionStartTime = new Date();
    
    if (callInfo) {
      this.fromNumber = callInfo.from;
      this.toNumber = callInfo.to;
      this.fromCountry = callInfo.fromCountry;
      this.toCountry = callInfo.toCountry;
      this.fromLocation = `${callInfo.fromCity}, ${callInfo.fromState}`.replace(', ', '');
      
      // Create Dialogflow session ID using phone number for conversation continuity
      this.dialogflowSessionId = dialogflowService.generateSessionIdFromPhone(this.fromNumber);
    } else {
      this.fromNumber = 'unknown';
      this.toNumber = 'unknown';
      this.fromCountry = 'unknown';
      this.toCountry = 'unknown';
      this.fromLocation = 'unknown';
      this.dialogflowSessionId = dialogflowService.generateSessionId();
    }
    
    console.log('\n' + 'üÜî'.repeat(30));
    console.log('üìã SESSION STARTED:');
    console.log('üÜî'.repeat(30));
    console.log(`üîë Session ID: ${this.sessionId}`);
    console.log(`üìû Call SID: ${this.callSid}`);
    console.log(`üåä Stream SID: ${this.streamSid}`);
    console.log(`üì± From: ${this.fromNumber} (${this.fromCountry})`);
    console.log(`üìû To: ${this.toNumber} (${this.toCountry})`);
    console.log(`üìç Location: ${this.fromLocation}`);
    console.log(`ü§ñ Dialogflow Session: ${this.dialogflowSessionId}`);
    console.log(`‚è∞ Started: ${this.sessionStartTime.toISOString()}`);
    console.log('üÜî'.repeat(30) + '\n');
  }

  addAudioChunk(base64Audio) {
    this.chunkCount++;
    const audioBuffer = Buffer.from(base64Audio, 'base64');
    this.audioChunks.push(audioBuffer);
    
    if (!this.isRecording) {
      this.isRecording = true;
      console.log('üé§ Started recording user query...');
      
      this.processingInterval = setInterval(() => {
        this.processAccumulatedAudio();
      }, this.processingIntervalTime);
    }

    if (this.chunkCount % 100 === 0) {
      console.log(`üì¶ Processed ${this.chunkCount} chunks so far...`);
    }
  }

  async processAccumulatedAudio() {
    const now = Date.now();
    
    console.log('üîç DEBUG - processAccumulatedAudio called');
    console.log(`üîç DEBUG - Time since last process: ${now - this.lastProcessTime}ms`);
    console.log(`üîç DEBUG - Audio chunks available: ${this.audioChunks.length}`);
    
    if (now - this.lastProcessTime < 3000) {
      console.log('‚è≠Ô∏è  Skipping - processed recently');
      return;
    }

    if (this.audioChunks.length < this.minChunksBeforeProcessing) {
      console.log(`‚è±Ô∏è  Not enough audio yet (${this.audioChunks.length} chunks, need ${this.minChunksBeforeProcessing})`);
      return;
    }

    console.log('\n' + 'üé§'.repeat(20));
    console.log(`üîÑ Processing audio for session: ${this.sessionId}`);
    console.log(`üìä Audio chunks: ${this.audioChunks.length}`);
    console.log(`‚è∞ Session duration: ${Math.round((now - this.sessionStartTime.getTime()) / 1000)}s`);
    
    const completeAudio = Buffer.concat(this.audioChunks);
    console.log(`üìä Audio size: ${completeAudio.length} bytes`);

    this.lastProcessTime = now;
    
    console.log('üîç DEBUG - About to call transcribeAudioMulaw...');
    await this.transcribeAudioMulaw(completeAudio);
    console.log('üîç DEBUG - transcribeAudioMulaw completed');

    this.audioChunks = [];
    this.chunkCount = 0;
    console.log('üîÑ Ready for next audio segment...\n');
  }

  async transcribeAudioMulaw(mulawBuffer) {
    try {
      console.log(`üîç Transcribing audio for caller: ${this.fromNumber}`);
      console.log(`üîä DEBUG - Buffer length: ${mulawBuffer.length} bytes`);
      
      if (mulawBuffer.length === 0) {
        console.log('‚ùå Empty audio buffer');
        return;
      }
      
      const base64Audio = mulawBuffer.toString('base64');
      console.log(`üîä DEBUG - Base64 audio length: ${base64Audio.length}`);
      
      const request = {
        audio: { content: base64Audio },
        config: {
          encoding: 'MULAW',
          sampleRateHertz: 8000,
          languageCode: 'en-US',
          model: 'phone_call',
          useEnhanced: true,
          enableAutomaticPunctuation: true,
          maxAlternatives: 1,
        },
      };

      console.log('üîç DEBUG - Sending request to Google Speech API...');
      const [response] = await speechClient.recognize(request);
      
      console.log('üîç DEBUG - Google Speech API response received');
      console.log('üîç DEBUG - Response results length:', response.results?.length || 0);
      
      if (response.results && response.results.length > 0) {
        console.log('üîç DEBUG - Processing speech results...');
        
        const transcription = response.results
          .map(result => result.alternatives[0].transcript)
          .join(' ')
          .trim();
        
        const confidence = response.results[0].alternatives[0].confidence || 0;
        
        console.log(`üîç DEBUG - Raw transcription: "${transcription}"`);
        console.log(`üîç DEBUG - Confidence: ${(confidence * 100).toFixed(1)}%`);
        
        // LOWER THE CONFIDENCE THRESHOLD FOR DEBUGGING
        if (transcription === '' || confidence < 0.1) { // Changed from 0.3 to 0.1
          console.log(`‚è≠Ô∏è  Skipping low quality transcription (confidence: ${(confidence * 100).toFixed(1)}%)`);
          console.log(`‚è≠Ô∏è  DEBUG - Transcription was: "${transcription}"`);
          return;
        }
        
        // TEMPORARY: Send everything to DialogFlow for debugging
        if (transcription === '') {
          console.log(`‚è≠Ô∏è  Empty transcription, skipping DialogFlow call`);
          return;
        }
        
        const timestamp = new Date().toISOString();
        
        console.log('\n' + '='.repeat(60));
        console.log('üéØ TRANSCRIPTION COMPLETED:');
        console.log('='.repeat(60));
        console.log(`üÜî Session: ${this.sessionId}`);
        console.log(`üì± From: ${this.fromNumber} (${this.fromLocation})`);
        console.log(`‚è∞ Time: ${timestamp}`);
        console.log(`üìù User Said: "${transcription}"`);
        console.log(`üìä Confidence: ${(confidence * 100).toFixed(1)}%`);
        console.log('='.repeat(60));
        
        console.log('üöÄ DEBUG - About to call sendToDialogflowAndLogResponse...');
        
        // üöÄ SEND TO DIALOGFLOW CX AND GET RESPONSE
        await this.sendToDialogflowAndLogResponse(transcription, confidence);
        
        console.log('üöÄ DEBUG - sendToDialogflowAndLogResponse completed');
        
      } else {
        console.log(`‚ùå No transcription results for session: ${this.sessionId}`);
        console.log('üîç DEBUG - Full Google Speech response:');
        console.log(JSON.stringify(response, null, 2));
      }
    } catch (error) {
      console.error(`‚ùå Transcription error for session ${this.sessionId}:`, error.message);
      console.error('üîç DEBUG - Full error:', error);
    }
  }

  async sendToDialogflowAndLogResponse(userMessage, confidence) {
    try {
      console.log('\n' + 'üöÄ'.repeat(25));
      console.log('ü§ñ SENDING TO DIALOGFLOW CX...');
      console.log('üöÄ'.repeat(25));
      console.log(`üìû Caller: ${this.fromNumber}`);
      console.log(`üÜî DF Session: ${this.dialogflowSessionId}`);
      console.log(`üí¨ Message: "${userMessage}"`);
      
      // Send to DialogFlow CX
      const dfResponse = await dialogflowService.sendMessage(
        userMessage, 
        this.dialogflowSessionId
      );
      
      console.log('\n' + 'üéâ'.repeat(25));
      console.log('ü§ñ DIALOGFLOW CX RESPONSE:');
      console.log('üéâ'.repeat(25));
      
      if (dfResponse.success) {
        console.log(`‚úÖ Success: true`);
        console.log(`üÜî Response ID: ${dfResponse.sessionId}`);
        
        // Log Intent Information
        if (dfResponse.intent) {
          console.log(`üéØ Intent Detected: ${dfResponse.intent.displayName}`);
          console.log(`üìä Intent Confidence: ${(dfResponse.intent.confidence * 100).toFixed(1)}%`);
        } else {
          console.log(`üéØ Intent: No intent detected`);
        }
        
        // Log Current Page
        if (dfResponse.currentPage) {
          console.log(`üìÑ Current Page: ${dfResponse.currentPage.displayName}`);
        }
        
        // Log Parameters
        if (dfResponse.parameters && Object.keys(dfResponse.parameters).length > 0) {
          console.log(`üìã Extracted Parameters:`);
          Object.entries(dfResponse.parameters).forEach(([key, value]) => {
            console.log(`   - ${key}: ${JSON.stringify(value)}`);
          });
        } else {
          console.log(`üìã Parameters: None extracted`);
        }
        
        // üé§ LOG THE MAIN RESPONSE MESSAGES
        console.log(`üó£Ô∏è  BOT RESPONSES:`);
        if (dfResponse.messages && dfResponse.messages.length > 0) {
          dfResponse.messages.forEach((message, index) => {
            console.log(`   ${index + 1}. "${message}"`);
          });
        } else {
          console.log(`   (No response messages)`);
        }
        
        console.log(`üåç Language: ${dfResponse.languageCode}`);
        
      } else {
        console.log(`‚ùå Success: false`);
        console.log(`üí• Error: ${dfResponse.error}`);
        console.log(`üó£Ô∏è  Fallback Response: ${dfResponse.messages.join(' ')}`);
      }
      
      console.log('üéâ'.repeat(25) + '\n');
      
      // Save the complete conversation exchange
      this.saveConversationLog({
        sessionId: this.sessionId,
        dialogflowSessionId: this.dialogflowSessionId,
        fromNumber: this.fromNumber,
        timestamp: new Date().toISOString(),
        userMessage: userMessage,
        userConfidence: confidence,
        dialogflowResponse: dfResponse,
        success: dfResponse.success
      });
      
    } catch (error) {
      console.error('\n‚ùå ERROR COMMUNICATING WITH DIALOGFLOW CX:');
      console.error(`üí• Error: ${error.message}`);
      console.error(`üìû Caller: ${this.fromNumber}`);
      console.error(`üí¨ Message that failed: "${userMessage}"`);
      console.error('Full error:', error);
    }
  }

  saveConversationLog(data) {
    try {
      const logFile = `conversations_${new Date().toISOString().split('T')[0]}.jsonl`;
      fs.appendFileSync(logFile, JSON.stringify(data) + '\n');
      console.log(`üíæ Conversation saved to: ${logFile}`);
    } catch (error) {
      console.error('‚ùå Failed to save conversation log:', error.message);
    }
  }

  async forceProcessAudio() {
    console.log('üîÑ Forcing final audio processing...');
    
    if (this.processingInterval) {
      clearInterval(this.processingInterval);
      this.processingInterval = null;
    }

    if (this.audioChunks.length > 0) {
      await this.processAccumulatedAudio();
    }
  }

  reset() {
    console.log(`üîÑ RESET called for session: ${this.sessionId || 'unknown'}`);
    
    if (this.sessionStartTime) {
      const duration = Math.round((Date.now() - this.sessionStartTime.getTime()) / 1000);
      console.log(`üìä Final Session Summary:`);
      console.log(`   üì± Caller: ${this.fromNumber}`);
      console.log(`   ü§ñ DF Session: ${this.dialogflowSessionId}`);
      console.log(`   ‚è∞ Duration: ${duration} seconds`);
      console.log(`   üìä Total Chunks: ${this.chunkCount}`);
    }
    
    if (this.callSid) {
      activeCalls.delete(this.callSid);
    }
    
    // Reset all properties
    this.audioChunks = [];
    this.isRecording = false;
    this.lastProcessTime = 0;
    this.chunkCount = 0;
    
    if (this.processingInterval) {
      clearInterval(this.processingInterval);
      this.processingInterval = null;
    }
    
    this.sessionId = null;
    this.callSid = null;
    this.streamSid = null;
    this.accountSid = null;
    this.fromNumber = null;
    this.toNumber = null;
    this.fromCountry = null;
    this.toCountry = null;
    this.fromLocation = null;
    this.sessionStartTime = null;
    this.dialogflowSessionId = null;
    
    console.log('üîÑ Ready for next call...\n');
  }
}

// Create audio buffer instance
const audioBuffer = new AudioBuffer();

// TwiML route
app.post("/twiml", (req, res) => {
  console.log("üìû TwiML request received");
  
  // const callInfo = {
  //   callSid: req.body.CallSid,
  //   from: req.body.From || req.body.Caller,
  //   to: req.body.To || req.body.Called,
  //   fromCountry: req.body.FromCountry,
  //   toCountry: req.body.ToCountry,
  //   fromState: req.body.FromState,
  //   toState: req.body.ToState,
  //   fromCity: req.body.FromCity,
  //   toCity: req.body.ToCity,
  //   accountSid: req.body.AccountSid,
  //   callStatus: req.body.CallStatus,
  //   direction: req.body.Direction
  // };
  
  // activeCalls.set(callInfo.callSid, callInfo);
  
  // console.log('üìã INCOMING CALL:');
  // console.log(`üîë Call SID: ${callInfo.callSid}`);
  // console.log(`üì± From: ${callInfo.from} (${callInfo.fromCountry})`);
  // console.log(`üìû To: ${callInfo.to}`);
  // console.log(`üìç Location: ${callInfo.fromCity}, ${callInfo.fromState}`);
  
  const filePath = path.join(__dirname, "templates", "streams.xml");
  res.type("text/xml");
  res.sendFile(filePath);
});

// WebSocket connection handler
mediaws.on("connect", function (connection) {
  console.log("üìû Twilio WebSocket connected");

  connection.on("message", function (message) {
    if (message.type === "utf8") {
      try {
        const data = JSON.parse(message.utf8Data);
        
        if (data.event === "connected") {
          console.log("‚úÖ Twilio stream connected");
        } else if (data.event === "start") {
          console.log("üé§ Audio stream started");
          
          const sessionInfo = {
            callSid: data.start.callSid,
            streamSid: data.start.streamSid,
            accountSid: data.start.accountSid
          };
          
          const callInfo = activeCalls.get(sessionInfo.callSid);
          
          audioBuffer.reset();
          audioBuffer.setSessionInfo(sessionInfo, callInfo);
          
        } else if (data.event === "media" && data.media && data.media.payload) {
          audioBuffer.addAudioChunk(data.media.payload);
        } else if (data.event === "stop") {
          console.log("üõë Audio stream stopped - forcing final processing");
          audioBuffer.forceProcessAudio();
        }
      } catch (error) {
        console.error("‚ùå Error parsing WebSocket message:", error);
      }
    }
  });

  connection.on("close", function () {
    console.log("üìû Twilio WebSocket disconnected");
    audioBuffer.forceProcessAudio().then(() => {
      audioBuffer.reset();
    });
  });
});

app.get("/ping", (req, res) => {
  const timestamp = new Date().toISOString();
  const uptime = process.uptime();
  
  console.log(`üèì Ping received at ${timestamp}`);
  
  res.json({
    status: "ok",
    message: "Voice + DialogFlow CX Server is running",
    timestamp: timestamp,
    uptime: `${Math.floor(uptime)} seconds`,
    services: {
      speech: "Google Cloud Speech-to-Text",
      dialogflow: "DialogFlow CX",
      websocket: "Twilio WebSocket"
    },
    endpoints: {
      ping: "/ping",
      twiml: "/twiml",
      websocket: `ws://localhost:${HTTP_SERVER_PORT}`
    }
  });
});



// Start server
server.listen(HTTP_SERVER_PORT, function () {
  console.log('\n' + 'üöÄ'.repeat(20));
  console.log("üéâ VOICE + DIALOGFLOW CX SERVER STARTED");
  console.log('üöÄ'.repeat(20));
  console.log(`üåê Server: http://localhost:${HTTP_SERVER_PORT}`);
  console.log(`üì° WebSocket: ws://localhost:${HTTP_SERVER_PORT}`);
  console.log(`üìÑ TwiML: http://localhost:${HTTP_SERVER_PORT}/twiml`);
  console.log(`ü§ñ DialogFlow CX: ${dialogflowService.projectId}`);
  console.log("üé§ Ready to process calls and chat with AI!");
  console.log('üöÄ'.repeat(20) + '\n');
});